[{"title":"我们为什么需要知识图谱？为什么数据表就不行了？","url":"/2019/09/15/我们为什么需要知识图谱/","content":"\n### 知识图谱\n\n知识图谱于2012年5月17日由Google正式提出，其初衷是为了提高搜索引擎的能力。随着人工智能的技术发展和应用，作为关键技术之一，已被广泛应用于智能搜索、智能问答、个性化推荐、内容分发等领域。\n\n知识图谱在本质上是描述实体间关系的语义网络，图数据库对于它来说是一个很好的容器。相似的，知识图谱的节点表示实体或概念，边则由属性或关系构成。根据覆盖范围而言，知识图谱可分为开放域通用知识图谱和垂直行业知识图谱。\n\n知识图谱中的基本概念：\n\n实体: 指的是具有可区别性且独立存在的某种事物。如某一个人、某一个城市、某一种植物等、某一种商品等等。世界万物有具体事物组成，此指实体。如图1的“中国”、“美国”、“日本”等。，实体是知识图谱中的最基本元素，不同的实体间存在不同的关系。\n\n语义类（概念）：具有同种特性的实体构成的集合，如国家、民族、书籍、电脑等。 概念主要指集合、类别、对象类型、事物的种类，例如人物、地理等。\n\n内容: 通常作为实体和语义类的名字、描述、解释等，可以由文本、图像、音视频等来表达。\n\n属性(值): 从一个实体指向它的属性值。不同的属性类型对应于不同类型属性的边。属性值主要指对象指定属性的值。如图1所示的“面积”、“人口”、“首都”是几种不同的属性。属性值主要指对象指定属性的值，例如960万平方公里等。\n\n关系: 形式化为一个函数，它把k个点映射到一个布尔值。在知识图谱上，关系则是一个把k个图节点(实体、语义类、属性值)映射到布尔值的函数。\n\n基于上述定义，三元组是知识图谱的一种通用表示方式，如下图所示，中国是一个实体，北京是一个实体，中国-首都-北京 是一个（实体-关系-实体）的三元组样例。北京是一个实体 ，人口是一种属性2069.3万是属性值。北京-人口-2069.3万构成一个（实体-属性-属性值）的三元组样例。\n\n![微信图片_20170930152906.jpg](http://www.talkwithtrend.com/home/attachment/201709/30/938893_150675655515508.jpg)\n\n知识图谱用节点和关系所组成的图谱，为真实世界的各个场景直观地建模，运用“图”这种基础性、通用性的“语言”，“高保真”地表达这个多姿多彩世界的各种关系，并且非常直观、自然、直接和高效，不需要中间过程的转换和处理——这种中间过程的转换和处理，往往把问题复杂化，或者遗漏掉很多有价值的信息。总结起来，图数据库中存储的知识图谱有以下几个优势：\n\n（1）关系的表达能力强\n\n传统数据库通常通过表格、字段等方式进行读取，而关系的层级及表达方式多种多样，且基于图论和概率图模型，可以处理复杂多样的关联分析，满足企业各种角色关系的分析和管理需要。\n\n（2）像人类思考一样去做分析\n\n基于知识图谱的交互探索式分析，可以模拟人的思考过程去发现、求证、推理，业务人员自己就可以完成全部过程，不需要专业人员的协助。\n\n（3）知识学习\n\n利用交互式机器学习技术，支持根据推理、纠错、标注等交互动作的学习功能，不断沉淀知识逻辑和模型，提高系统智能性，将知识沉淀在企业内部，降低对经验的依赖。\n\n（4）高速反馈\n\n图式的数据存储方式，相比传统存储方式，数据调取速度更快，图库可计算超过百万潜在的实体的属性分布，可实现秒级返回结果，真正实现人机互动的实时响应，让用户可以做到即时决策。\n\n然而知识图谱仅仅是纸上谈兵，在应用实践中落地则需要图数据库为其提供肉身。\n\n### 图数据库\n\n在数据结构中，图是由节点和关系两个元素构成，图数据库同样由这两部分构成。其中，节点表示实体（人、物、地点等），关系则代表两个实体之间的联系。\n\n图数据库是一种非关系型数据库，它应用图形理论存储实体之间的关系信息。最常见例子就是社会网络中人与人之间的关系。关系型数据库用于存储“关系型”数据的效果并不好，可以说关系型数据库是最不擅长存储关系的数据库，其查询复杂、缓慢，而图形数据库的独特设计恰恰弥补了这个缺陷。\n\n举个例子：假设某关系型数据库中有这么几张用户、订单、商品表：\n\n![image](https://s3.amazonaws.com/dev.assets.neo4j.com/wp-content/uploads/20180716185458/relational-database-rdbms-model-example.jpg)\n\n当我们要查询：“用户购买了那些商品？” 或者 “该商品有哪些客户购买过？” 需要开发人员JOIN几张表，效率非常低下。而“购买该产品的客户还购买了哪些商品？”类似的查询则更难实现。\n\n关系型数据库需要表示多对多关系时，我们常常需要创建一个关联表来记录不同实体的多对多关系，而且这些关联表常常不用来记录信息。如果两个实体之间拥有多种关系，那么我们就需要在它们之间创建多个关联表。而在图数据库中，我们只需要在两个实体节点之间建立一条有向的线来表示某种关系。相对于关系数据库中的各种关联表，图形数据库中的关系可以通过关系能够包含属性这一功能来提供更为丰富的关系展现方式。标记属性图模型：\n\n![关系属性](https://s3.amazonaws.com/dev.assets.neo4j.com/wp-content/uploads/20170731095054/Property-Graph-Concepts-Simple.svg)\n\n由此可以看出，在面对大量的实体和关系时，在理论上图数据库已经展示出了更有效的存储和查询。在实践中，《Neo4j in Action》这本书的作者在关系型数据库和图数据库(Neo4j)之间进行了实验：\n\n![image](https://s2.ax1x.com/2019/02/21/kR4tKg.md.png)\n\n他们的实验试图在一个社交网络里找到最大深度为5的朋友的朋友。他们的数据集包括100万人，每人约有50个朋友。实验结果如下：\n\n| 深度 | MySQL执行时间(s) | Neo4j执行时间(s) | 返回记录数 |\n| ---- | ---------------- | ---------------- | ---------- |\n| 2    | 0.016            | 0.01             | ~2500      |\n| 3    | 30.267           | 0.168            | ~110 000   |\n| 4    | 1543.505         | 1.359            | ~600 000   |\n| 5    | 未完成           | 2.132            | ~800 000   |\n\n在深度为2时（即朋友的朋友），两种数据库性能相差不是很明显；深度为3时(即朋友的朋友的朋友)，很明显，关系型数据库的响应时间30s，已经变得不可接受了；深度到4时，关系数据库需要近半个小时才能返回结果，使其无法应用于在线系统；深度到5时，关系型数据库已经无法完成查询。而对于图数据库Neo4j，深度从3到5，其响应时间均在3秒以内。\n\n可以看出，对于图数据库来说，数据量越大，越复杂的关联查询，约有利于体现其优势。从深度为4/5的查询结果我们可以看出，图数据库返回了整个社交网络一半以上的人数，而关系型数据库此时已经束手无策。\n\n从上文中我们可以看出，知识图谱更偏向于理论，图数据库更像一个容器或物理实现。知识图谱的很多优势都依赖于图数据库的存储方式，图数据库为知识图谱的大范围实际应用提供了可能。\n\n### 面临的问题与挑战\n\n知识图谱的构建：大规模知识的自动抽取技术仍处于基础阶段，虽然近年得益于深度学习的快速发展，使得自然语言处理技术有了很大的进步，对于测试数据取得了不错的效果，但在真实的应用环境中，知识抽取的准确性仍然有待提高。目前的工业实践中，仍需要投入大量人力进行知识标注。\n\n知识图谱的存储：虽然目前图数据库已经可以用于知识图谱的存储，但对于海量的不断增长的数据，在存储、查询、更新方面依然有待提高。\n\n知识推理：知识图谱作为人工智能的知识基石，实现实体间关系的自动推理是机器更加智能化的必经之路，而在这方面，我们的技术和人的大脑还差很远，尤其是在人类世界常识方面。\n\n参考：\n\n- [百度百科-图形数据库](https://baike.baidu.com/item/%E5%9B%BE%E5%BD%A2%E6%95%B0%E6%8D%AE%E5%BA%93/5199451)\n- [越来越火的图数据库究竟是什么？](https://www.cnblogs.com/mantoudev/p/10414495.html)\n- 最全知识图谱综述: 概念以及构建技术\n\n\n\n","tags":["knowledge graph","graph database"],"categories":["Knowledge Graph"]},{"title":"在Manjaro Linux中安装TexLive","url":"/2019/08/04/manjaro-install-texlive/","content":"\n## 前言\n\n最近开始尝试使用Latex进行论文写作，根据网友推荐，选择Texlive作为基本环境，windows机器上可以很方便的安装Texlive，在Manjaro Linux系统下也不算复杂，我将我的安装过程写在这里与大家分享。\n\n## 方法一\n\n推荐使用方法二。\n\n### 安装Perl组件\n\n终端运行以下命令：\n\n```bash\nsudo pacman -S perl-tk\n```\n\n### 下载iso文件\n\n在清华大学镜像站下载：https://mirrors.tuna.tsinghua.edu.cn/CTAN/systems/texlive/Images/ \n\n我选择的是 texlive2019.iso，点击即开始下载，3.3G有点大。\n\n### 加载iso文件\n\n终端运行以下命令：\n\n```bash\nsudo mount -o loop /path/to/texlive2019-20190410.iso /mnt\n```\n\n如果提示：mount: /mnt: 警告：设备写保护，使用只读方式挂载. 忽略即可。\n\n### 启动安装界面\n\n终端执行以下命令：\n\n```bash\ncd /mnt\nsudo ./install-tl -gui\n```\n\n出现图形化安装界面，一般不需进行个性化设置，点击安装即可，喝杯水耐心等待安装完成。\n\n添加环境变量，运行以下命令：\n\n```bash\nsudo nano ~/.bashrc\n```\n\n在文件末尾，添加如下内容：\n\n```bash\n# texlive 2019\nexport MANPATH=${MANPATH}:/usr/local/texlive/2019/texmf-dist/doc/man\nexport INFOPATH=${INFOPATH}:/usr/local/texlive/2019/texmf-dist/doc/info\nexport PATH=${PATH}:/usr/local/texlive/2019/bin/x86_64-linux\n```\n\n别忘记卸载镜像：\n\n```bash\nsudo umount /mnt/\n```\n\n测试，新建test.tex文件，添加如下内容：\n\n```latex\n\\documentclass{article}\n\\begin{document}\nhello \\LaTeX\n\\end{document}\n```\n\n然后在终端运行以下命令：\n\n```bash\nxelatex /path/to/test.tex\n```\n\n如安装成功，得到如下输出：\n\n```bash\nThis is XeTeX, Version 3.14159265-2.6-0.999991 (TeX Live 2019) (preloaded format=xelatex)\n restricted \\write18 enabled.\nentering extended mode\n(./textest.tex\nLaTeX2e <2018-12-01>\n(/usr/local/texlive/2019/texmf-dist/tex/latex/base/article.cls\nDocument Class: article 2018/09/03 v1.4i Standard LaTeX document class\n(/usr/local/texlive/2019/texmf-dist/tex/latex/base/size10.clo))\nNo file textest.aux.\n[1] (./textest.aux) )\nOutput written on textest.pdf (1 page).\nTranscript written on textest.log.\n```\n\n## 方法二\n\nArchlinux已经有了有关texlive的包，简单的方法就是执行以下命令直接安装：\n\n```bash\nsudo pacman -S texlive-most\n```\n\n具体可以参考：https://wiki.archlinux.org/index.php/TeX_Live 。\n\n### 安装TexStudio\n\n终端执行以下命令：\n\n```bash\nsudo pacman -S texstudio\n```\n\n安装完成后可以在options中设置为中文界面，以及选择默认的编译器。\n\n用第一种方法安装，可能会导致TexStudio检索不到TexLive，推荐使用第二种方法安装。\n\n现在就可以开始Latex文章的撰写了！\n","tags":["manjaro","latex"],"categories":["Linux"]},{"title":"Manjaro安装与优化全记录","url":"/2019/08/03/Manjaro安装与优化全记录/","content":"\n### 前言\n\n之前用过一段时间的linux后，又回到了windows。最近假期又起了折腾之心，想要回到linux的怀抱，于是就尝试了一下新火的manjaro，特此记录，与大家分享。\n\n### 安装manjaro\n\n首先从官网下载所需镜像，我选择的是gnome版本，大家可以根据个人喜好和机器配置进行选择。\n\nlinux系统下可以直接使用dd命令，windows用户可以使用rufus软件将镜像写入U盘，具体参考百度。\n\nU盘启动盘制作好后插入电脑，重启电脑，开机界面出现后按快捷键进入启动盘选择界面，按上下键选择U盘启动，我的联想笔记本快捷键是F12，大家可以根据自己的电脑型号自行查找快捷键。\n\nU盘启动之后，第一步使用enter和上下键选择时区、语言，然后点击第五项Boot，进入下一步。\n\n如果需要，可以在窗口左上角可以选择语言Chinese，选择启动安装程序，然后一直点击下一步，根据自己情况设置安装硬盘和分区。\n\n最后等待安装完成，拔掉U盘，重启电脑即可进入焕然一新的Manjaro。\n\n接下来我们完成基本的设置和安装一些必备软件。\n\n### 更换源\n\n寻找国内最快源：\n\n```bash\nsudo pacman-mirrors -c China\n```\n\nsudo nano `/etc/pacman.conf`，末尾添加两行：\n\n```\n[archlinuxcn]\nServer = https://mirrors.ustc.edu.cn/archlinuxcn/$arch\n```\n\n### 更新系统\n\n```bash\n sudo pacman -Syu\n```\n\n### 安装`archlinuxcn-keyring`:\n\n```bash\n sudo pacman -S archlinuxcn-keyring\n sudo pacman -Syu\n```\n\n### 修改Home下的目录为英文\n\n修改目录映射文件名；\n\n```bash\nsudo nano ~/.config/user-dirs.dirs\n```\n\n修改为以下内容：\n\n```\nXDG_DESKTOP_DIR=\"$HOME/Desktop\"\nXDG_DOWNLOAD_DIR=\"$HOME/Download\"\nXDG_TEMPLATES_DIR=\"$HOME/Templates\"\nXDG_PUBLICSHARE_DIR=\"$HOME/Public\"\nXDG_DOCUMENTS_DIR=\"$HOME/Documents\"\nXDG_MUSIC_DIR=\"$HOME/Music\"\nXDG_PICTURES_DIR=\"$HOME/Pictures\"\nXDG_VIDEOS_DIR=\"$HOME/Videos\"\n```\n\n将Home目录下的中文目录名改为对应的中文名；\n\n```bash\ncd ~\nmv 公共 Public\nmv 模板 Templates\nmv 视频 Videos\nmv 图片 Pictures\nmv 文档 Documents\nmv 下载 Download\nmv 音乐 Music\nmv 桌面 Desktop\n```\n\n重启系统。\n\n### 安装搜狗输入法\n\n```bash\n sudo pacman -S fcitx-im    #全部安装\n sudo pacman -S fcitx-configtool\n sudo pacman -S fcitx-sogoupinyin\n```\n\nsudo nano ~/.xprofile`文件，加入如下内容：\n\n```\nexport GTK_IM_MODULE=fcitx\nexport QT_IM_MODULE=fcitx\nexport XMODIFIERS=\"@im=fcitx\"\n```\n\n之后，自行百度安装Chrome、QQ、Wechat、网易云音乐、WPS等，这些可网上的命令直接安装，一路顺畅没有遇到问题。\n\n### 更换主题和图标\n\n系统自带了gnome-tweak-tool，名字为“优化”，可以用来更换主题和进行个性化设置。\n\n推荐在 https://www.gnome-look.org/ 下载自己喜欢的主题，下载好压缩包之后解压，然后以管理员身份打开/usr/share/themes文件夹，将解压后得到的文件夹复制进去。\n\n打开“优化”，即可选择自己安装的主题，我使用的是Ant Dracula主题。\n\n另外，从github中下载主题需要自行编译，不推荐。\n","tags":["manjaro","linux"],"categories":["Linux"]},{"title":"Centos下搭建Django网站环境","url":"/2019/04/20/django-nginx-uwsgi-server/","content":"\n### 前言\n\n作为django网站开发的学习者，这是我在搭建Centos-Django-Nginx-Uwsgi服务器时留下的笔记。在搭建过程中，参考了大量的网上教程，但是没有一篇能完整地带我正确地走过全部流程，大坑小坑不计其数，因此在这里和大家分享一下我搭建过程中的整个流程，希望对学习者有所帮助。\n\n### 安装Python3.6\n\n- 安装依赖工具\n\n  ```\n  sudo yum install openssl-devel bzip2-devel expat-devel gdbm-devel readline-devel sqlite-devel mysql-devel gcc gcc-devel python-devel\n  ```\n\n- 下载python3.6.8\n\n  ```\n  wget https://www.python.org/ftp/python/3.6.8/Python-3.6.8.tgz\n  ```\n\n- 解压\n\n  ```\n  tar -zxvf Python-3.6.8.tgz\n  ```\n\n- 将python移动至规范的软件安装目录\n\n  ```\n  sudo mv Python-3.6.8 /usr/local\n  ```\n\n- 编译安装python\n\n  ```\n  cd /usr/local/Python-3.6.8/\n  ./configure\n  make\n  sudo make install\n  ```\n\n### 安装虚拟环境\n\n- 安装virtualenvwrapper\n\n  ```\n  # update pip\n  sudo /usr/local/bin/pip3 install --upgrade pip\n  sudo /usr/local/bin/pip3 install virtualenv\n  sudo /usr/local/bin/pip3 install virtualenvwrapper\n  ```\n\n- 创建目录存放虚拟环境\n\n  ```\n  mkdir $HOME/.virtualenvs\n  ```\n\n- 修改~/.bashrc文件\n\n  ```\n  sudo vim~/.bashrc\n  # 添加下面的内容\n  export WORKON_HOME=$HOME/.virtualenvs\n  export VIRTUALENVWRAPPER_PYTHON=/usr/local/bin/python3.6\n  source /usr/local/bin/virtualenvwrapper.sh\n  ```\n\n- 运行\n\n  ```\n  source ~/.bashrc\n  ```\n\n- 创建并进入虚拟环境\n\n  ```\n  mkvirtualenv myenv\n  ```\n\n### 安装Django并创建项目\n\n- 虚拟环境下安装Django==1.11.20\n\n  ```\n  pip install django==1.11.20\n  ```\n\n- 创建项目\n\n  ```\n  # 进入放置项目的文件夹\n  cd /home/root/pydj\n  sudo /home/admin/.virtualenvs/myenv/bin/django-admin startproject mysite\n  ```\n\n- 获取文件夹权限，防止runserver时数据库出错\n\n  ```\n  sudo chmod -R 777 /home/root/pydj\n  ```\n\n- 将你的服务器ip添加到settings.py，避免外网访问错误\n\n  ```\n  ALLOWED_HOSTS = ['myip']\n  ```\n\n- 试运行项目，不指定0.0.0.0外网访问会出错\n\n  ```\n  python manage.py runserver 0.0.0.0:8000\n  ```\n\n  访问：http://myip:8000 可以看到：\n\n  ```\n  It worked!\n  Congratulations on your first Django-powered page.\n  Next, start your first app by running python manage.py startapp [app_label].\n  You're seeing this message because you have DEBUG = True in your Django settings file and you haven't configured any URLs. Get to work!\n  ```\n\n### uWSGI的安装和配置\n\n- 虚拟环境下安装uWSGI\n\n  ```\n  pip install uwsgi\n  ```\n\n- 测试\n\n  创建一个test.py文件，内容如下：\n\n  ```\n  def application(env, start_response):\n      start_response('200 OK', [('Content-Type','text/html')])\n      return [b\"Hello World\"] # python3\n      #return [\"Hello World\"] # python2\n  ```\n\n  运行uWSGI:\n\n  ```\n  uwsgi --http :8000 --wsgi-file test.py\n  ```\n\n  访问 http://myip:8000 可以看到：Hello World\n\n- 使用uWSGI运行Django项目\n\n  ```\n  uwsgi --http :8000 --module mysite.wsgi\n  ```\n\n### nginx的安装和配置\n\n- 安装nginx\n\n  ```\n  # 安装nginx源\n  sudo rpm -ivh http://nginx.org/packages/centos/7/noarch/RPMS/nginx-release-centos-7-0.el7.ngx.noarch.rpm\n  安装nginx\n  yum install -y nginx\n  ```\n\n- 测试\n\n  ```\n  sudo nginx\n  ```\n\n  浏览器打开ip地址可以看到Welcome to nginx!\n\n- 进入django项目文件夹，创建uwsgi_params文件，添加如下内容：\n\n  ```\n  uwsgi_param  QUERY_STRING       $query_string;\n  uwsgi_param  REQUEST_METHOD     $request_method;\n  uwsgi_param  CONTENT_TYPE       $content_type;\n  uwsgi_param  CONTENT_LENGTH     $content_length;\n  \n  uwsgi_param  REQUEST_URI        $request_uri;\n  uwsgi_param  PATH_INFO          $document_uri;\n  uwsgi_param  DOCUMENT_ROOT      $document_root;\n  uwsgi_param  SERVER_PROTOCOL    $server_protocol;\n  uwsgi_param  REQUEST_SCHEME     $scheme;\n  uwsgi_param  HTTPS              $https if_not_empty;\n  \n  uwsgi_param  REMOTE_ADDR        $remote_addr;\n  uwsgi_param  REMOTE_PORT        $remote_port;\n  uwsgi_param  SERVER_PORT        $server_port;\n  uwsgi_param  SERVER_NAME        $server_name;\n  ```\n\n- 在 /etc/nginx/ 文件夹下创建 sites-enabled 文件夹，并在其下创建nginx.conf，添加如下内容：\n\n  ```\n  # nginx.conf\n  \n  # the upstream component nginx needs to connect to\n  upstream django {\n      # server unix:///path/to/your/mysite/mysite.sock; # for a file socket\n      server 127.0.0.1:8001; # for a web port socket (we'll use this first)\n  }\n  \n  # configuration of the server\n  server {\n      # the port your site will be served on\n      listen      80;\n      # the domain name it will serve for\n      server_name .example.com; # substitute your machine's IP address or FQDN\n      charset     utf-8;\n  \n      # max upload size\n      client_max_body_size 75M;   # adjust to taste\n  \n      # Django media\n      location /media  {\n          alias /path/to/your/mysite/media;  # your Django project's media files - amend as required\n      }\n  \n      location /static {\n          alias /path/to/your/mysite/static; # your Django project's static files - amend as required\n      }\n  \n      # Finally, send all non-media requests to the Django server.\n      location / {\n          uwsgi_pass  django;\n          include     /path/to/your/mysite/uwsgi_params; # the uwsgi_params file you installed\n      }\n  }\n  ```\n\n- 修改/etc/nginx/nginx.conf，在http下添加：\n\n  ```\n  include /etc/nginx/sites-enabled/*;\n  ```\n\n- 部署静态文件\n\n  在运行nginx之前，你必须收集所有的Django静态文件到静态文件夹里。首先，必须编辑mysite/settings.py，添加:\n\n  ```\n  STATIC_ROOT = os.path.join(BASE_DIR, \"static/\")\n  ```\n\n  然后运行\n\n  ```\n  python manage.py collectstatic\n  ```\n\n- 重启nginx\n\n  ```\n  sudo /usr/sbin/nginx -s reload\n  ```\n\n  此时打开 ip:8000 会出现502错误，因为nginx与uwsgi的socket通信还没开始。\n\n  虚拟环境下运行：\n\n  ```\n  uwsgi --socket :8001 --wsgi-file test.py\n  ```\n\n  此时，打开ip:8000可以看到Hello World。\n\n### 使用Unix sockets代替端口\n\n编辑sites-enabled文件夹下的nginx.conf文件，修改如下：\n\n```\nserver unix:///path/to/your/mysite/mysite.sock; # for a file socket  \n# server 127.0.0.1:8001; # for a web port socket (we'll use this first)\n```\n\n重启nginx。\n\n重新运行uWSGI：\n\n```\nuwsgi --socket mysite.sock --wsgi-file test.py --chmod-socket=666\n```\n\n### 使用uWSGI和Nginx运行django项目\n\n```\nuwsgi --socket mysite.sock --module mysite.wsgi --chmod-socket=666\n```\n\n现在uwsgi和nginx应该在服务你的Django应用，而不是hello world。\n\n### 配置uWSGI的ini文件\n\n- 项目文件夹下创建django_uwsgi.ini，添加以下内容：\n\n  ```\n  # django_uwsgi.ini file\n  [uwsgi]\n  \n  # Django-related settings\n  # the base directory (full path)\n  chdir           = /path/to/your/project  \n  # Django's wsgi file\n  module          = project.wsgi  \n  # the virtualenv (full path)\n  #home            = /path/to/virtualenv\n  \n  # process-related settings\n  # master\n  master          = true  \n  # maximum number of worker processes\n  processes       = 10  \n  # the socket (use the full path to be safe\n  socket          = mysite.sock  \n  # ... with appropriate permissions - may be needed\n  chmod-socket    = 666\n  # clear environment on exit\n  vacuum          = true\n  ```\n\n  使用如下命令运行：\n\n  ```\n  uwsgi --ini django_uwsgi.ini\n  ```\n\n### 附\n\n- 让uwsgi在后台运行：\n\n  ```\n  uwsgi --ini mysite_uwsgi.ini --logto mysite.log &\n  ```\n\n- 查看uwsgi进程\n\n  ```\n  ps aux|grep uwsgi\n  ```\n\n- 杀死uwsgi进程\n\n  ```\n  #停止进程\n  uwsgi --stop uwsgi.pid\n  #kill pid会发送SIGTERM，只会导致重启，而不是结束掉。需要发送SIGINT或SIGQUIT，对应着是INT才可以\n  killall -s INT uwsgi\n  ```\n\n以上就是在服务器中部署Django项目的所有过程，如有不当之处请指正。\n","tags":["django","web服务器"],"categories":["Django"]},{"title":"Attention Is All You Need !","url":"/2018/12/05/Attention Is All You Need !/","content":"\n### 前言\n由Google Brain在2017年发布的*Attention Is All You Need*使得自注意力机制走进大众视野，其应用逐渐由机器翻译领域，拓展到了自然语言处理中的各项技术。由于我在深度学习、关系抽取等反面的研究需求，对该论文进行了详细研究。本文作为阅读笔记，对其进行了详细梳理，希望能为大家对其理解提供帮助。\n\n![](/images/Attention Is All You Need !/1.jpg)\n\n### 摘要\n\n现存主要的序列转化模型都是基于复杂的循环神经网络或者卷积神经网络，它们都包含一个编码器和一个解码器。目前效果较好的模型，都是通过注意力机制来对编码器和解码器进行连接。我们提出一种新的简单网络架构Transformer，它仅仅基于注意力机制，完全抛弃了循环和卷积神经网络。两个机器翻译任务的实验表明，我们的模型在质量上更优越，同时更易于并行化，训练花费时间更短。在WMT 2014英语 - 德语翻译任务中达到28.4 BLEU，超过现有的最佳成绩，整体超过2 BLEU。在WMT 2014英语-法语翻译任务中，我们的模型在8个GPU上训练3.5天后，得到了一个新的单模型最高BLEU分数41.0。\n\n### 引言\n\n循环神经网络模型通常沿输入和输出序列的符号位置来进行计算。将位置与计算时的步骤对齐，产生隐藏状态ht序列，作为先前隐藏状态ht-1和位置t的输入的函数。这种固有的序列性质排除了样本训练并行化的可能，这在较长的序列中变得更为严重，因为内存约束限制了跨样本的批处理。最近的有研究通过分解技巧和条件计算实现了计算效率的显著提高，同时后者也提高了模型性能。然而，序列计算的基本约束仍然存在。\n\n注意力机制已成为多种任务序列建模和转化模型中引人注目的组成部分，它允许对依赖关系进行建模，而不用考虑它们在输入或输出序列中的距离。然而，多数情况下这种注意力机制与循环神经网络结合使用。\n\n在这项工作中，我们提出了Transformer，没有循环，而是完全依赖于注意力机制来描述输入和输出之间的全局依赖关系。Transformer允许更多的并行计算，并且在8个P100 GPU上训练了长达12小时后，可以达到一个新的最高翻译水平。\n\n### 背景\n\n减少序列计算的目标构成了Extended Neural GPU、ByteNet和ConvS2S的基础，它们都是将卷积神经网络作为基础模块，并行计算所有输入和输出位置的隐藏表达。在这些模型中，关联任意输入和输出位置符号的运算数量会随着距离的增加而增加，对于ConvS2S呈线性增长，对于ByteNet呈对数增长，这使得学习远距离之间的依赖性变得更加困难。在Transformer中，通过多头注意力将该运算数量被减少到了一个常量，尽管由于位置的平均注意加权而导致有效分辨率有所降低。\n\n自注意力，有时也称为内部注意力，是为计算序列表达关联单序列不同位置的注意力机制。自注意力机制已经被成功应用于阅读理解、文本摘要、文本推理以及学习与任务无关的句子表征等。\n\n端到端的记忆网络是基于循环attention机制，而不是序列对齐的循环，并且已被证明在简单语言问答和语言建模任务中表现良好。\n\n然而，据我们所知，Transformer是第一个用来计算输入和输出表征的完全依赖于自注意力机制的转化模型，该模型中无需使用序列对齐的RNN或CNN。\n\n### 模型架构\n\n这里，编码器映射一个用符号表示的输入序列(x1,...,xn) 到一个连续的表示z = (z1,...,zn)。根据z，解码器生成符号的一个输出序列(y1,...,ym) ，一次一个元素。在每一步中，模型都是自回归的，当生成下一个时，消耗先前生成的符号作为附加输入。\n\nTransformer遵循这种整体架构，编码器和解码器都使用self-attention堆叠和point-wise、完全连接的层，分别显示在图中的左半部分和右半部分。\n\n![](/images/Attention Is All You Need !/2.jpg)\n\n#### 编码器和解码器\n\n编码器：编码器由N = 6 个完全相同的层堆叠而成。每一层都有两个子层。第一层是一个多头自注意力机制，第二层是一个简单的、位置完全连接的前馈网络。我们对每个子层再采用一个残差连接，接着进行层标准化。也就是说，每个子层的输出是LayerNorm(x + Sublayer(x))，其中Sublayer(x) 是由子层本身实现的函数。为了方便这些残差连接，模型中的所有子层以及嵌入层产生的输出维度都为dmodel = 512。\n\n解码器：解码器同样由N = 6 个完全相同的层堆叠而成。除了每个编码器层中的两个子层之外，解码器还插入第三个子层，该层对编码器堆栈的输出执行多头自注意力。与编码器类似，我们在每个子层再采用残差连接，然后进行层标准化。我们还修改解码器堆栈中的自注意力子层，以防止位置关注到后面的位置。这种掩码结合将输出嵌入偏移一个位置，确保对位置 i 的预测只能依赖位置小于 i 的已知输出。\n\n#### 注意力机制\n\nAttention函数可以描述为将query和一组key-value对映射到输出，其中query、key、value和输出都是向量。输出是value的加权和，其中分配给每个value的权重通过query与相应key的兼容函数来计算。\n\n##### 缩放点积注意力\n\n我们称我们的特殊版的Attention为“Scaled Dot-Product Attention”。输入由query、dk 维的key和dv 维的value组成。我们计算query和所有key的点积、并分别用√dk相除，然后应用一个softmax函数以获得值的权重。\n\n![](/images/Attention Is All You Need !/3.png)\n\n在实践中，我们同时计算一组query的attention函数，并将它们组合成一个矩阵Q。 key和value也一起打包成矩阵 K 和 V 。我们计算输出矩阵为：\n\n![](/images/Attention Is All You Need !/4.jpg)\n\n两个最常用的attention函数是加法attention和点积attention。除了缩放因子1/ √dk之外，点积attention与我们的算法相同。加法attention使用具有单个隐藏层的前馈网络计算兼容性函数。虽然两者在理论上的复杂性相似，但在实践中点积attention的速度更快、更节省空间，因为它可以使用高度优化的矩阵乘法代码来实现。\n\n当dk的值比较小的时候，这两个机制的性能相近，当dk比较大时，加法attention比不带缩放的点积attention性能好。我们怀疑，对于很大的dk值，点积大幅度增长，将softmax函数推向具有极小梯度的区域。为了抵消这种影响，我们缩小点积1/√dk倍。\n\n##### 多头注意力\n\n我们发现将query、key和value分别用不同的、学到的线性投影，投影h倍到dk、dk和dv维效果更好，而不是用dmodel维的query、key和value执行单个attention函数。基于每个投影版本的query、key和value，我们并行执行attention函数，产生dv 维输出值。将它们连接并再次映射，产生最终值。\n\n多头注意力机制允许模型联合关注不同位置的不同表示子空间信息。如果只有一个attention head，它的平均值会削弱这个信息。\n\n![](/images/Attention Is All You Need !/5.jpg)\n\n我们采用h = 8 个并行attention层或head。对每个head，我们使用dk =dv =dmodel ∕ h = 64。由于每个head的大小减小，总的计算成本与具有全部维度的单个head attention相似。\n\n##### 本模型中的注意力\n\nTransformer中通过以下三种不同的方式来使用多头注意力：\n\n- 在“encoder-decoder attention”层，query来自前一个解码器层，key和value来自编码器的输出，这允许解码器中的每个位置能关注到输入序列中的所有位置。这模仿序列到序列模型中典型的编码器-解码器的attention机制。\n\n- 编码器包含self-attention层。在self-attention层中，所有的key、value和query来自同一个地方，在这里就是来自于编码器中前一层的输出。编码器中的每个位置都可以关注编码器上一层的所有位置。\n\n- 类似地，解码器中的self-attention层允许解码器中的每个位置都关注到解码器中的所有位置并包括该位置。我们需要防止解码器中的向左信息流来保持自回归属性。通过屏蔽softmax的输入中所有不合法连接的值（设置为-∞），我们在缩放点积attention中实现。\n\n#### 基于位置的前馈网络\n\n除了attention子层之外，我们的编码器和解码器中的每个层都包含一个全连接的前馈网络，该前馈网络单独且相同地应用于每个位置。它由两个线性变换组成，之间有一个ReLU激活函数。\n\n![](/images/Attention Is All You Need !/6.jpg)\n\n尽管线性变换在不同位置上是相同的，但层与层之间使用的是不同的参数。它的另一种描述方式是两个内核大小为1的卷积。输入和输出的维度为dmodel = 512，内部层的维度为dff = 2048。\n\n#### 嵌入和Softmax\n\n与其他序列转化模型相似，我们使用学习到的嵌入将输入词符和输出词符转化为dmodel维的向量。我们还使用普通的线性变换和softmax函数将解码器输出转换为预测的下一个词符的概率。在我们的模型中，两个嵌入层之间和pre-softmax线性变换共享相同的权重矩阵。在嵌入层中，我们将这些权重乘以√dmodel。\n\n#### 位置编码\n\n由于我们的模型不包含RNN和CNN，为了使得模型能够利用序列顺序，我们必须注入序列中关于词符相对或者绝对位置的一些信息。为此，我们将“位置编码”添加到编码器和解码器堆栈底部的输入嵌入中。位置编码和嵌入拥有相同的dmodel维度，所以它们俩可以相加。\n\n我们有多种位置编码可以选择，此工作中，我们使用不同频率的正弦和余弦函数：\n\n![](/images/Attention Is All You Need !/7.jpg)\n\n其中 *pos* 是位置，*i* 是维度。也就是说，位置编码的每个维度对应于一个正弦曲线。这些波长形成一个几何级数，从2π 到10000 ⋅ 2π。我们选择这个函数是因为我们假设它允许模型很容易学习对相对位置的关注，因为对任意确定的偏移k, *PEpos+k*可以表示为PEpos的线性函数。\n\n我们还使用学习到的位置嵌入进行了试验，发现这两个版本产生几乎相同的结果（参见表 3 行(E)）。我们选择了正弦曲线，因为它可以允许模型推断比训练期间遇到的更长的序列。\n\n### 为什么是自注意力机制\n\n本节，我们比较self-attention与循环层和卷积层的各个方面，它们通常用于映射一个可变长度符号序列表示(x1,...,xn) 到另一个等长的序列(z1,...,zn)，其中xi,zi ∈ ℝd，例如一个典型的序列转化编码器或解码器中的隐藏层。我们使用self-attention是考虑到解决三个问题。\n\n一个是每层计算的总复杂度。另一个是可以并行的计算量，以所需的最小序列运算的数量来衡量。\n\n第三个是网络中长距离依赖之间的路径长度。学习长距离依赖性是许多序列转化任务中的关键挑战。影响学习这种依赖性能力的一个关键因素是前向和后向信号必须在网络中传播的路径长度。输入和输出序列中任意位置组合之间的这些路径越短，学习远距离依赖性就越容易。因此，我们还比较了由不同层类型组成的网络中任意两个输入和输出位置之间的最大路径长度。\n\n![](/images/Attention Is All You Need !/8.jpg)\n\n如表1所示，self-attention层通过恒定数量的序列运算将所有位置连接在一起，而RNN层需要O(n) 序列运算。在计算复杂性方面，序列长度n 小于表示维度d 在机器翻译领域较为先进的模型中是最为常见的，例如单词表示法和字节对表示法，如表中所示这种情况下self-attention层比RNN层快。为了提高涉及很长序列的任务的计算性能，可以将self-attention限制在仅考虑大小为r 的邻域。这会将最大路径长度增加到O(n ∕ r)。我们计划在未来的工作中进一步探讨这种方法。\n\n核宽度为k < n的单层卷积不会连接每一对输入和输出的位置。要这么做，在邻近核的情况下需要O(n∕k) 个卷积层， 在扩展卷积的情况下需要O(logk(n)) 个层，它们增加了网络中任意两个位置之间的最长路径的长度。卷积层通常比循环层更昂贵，与因子k有关。然而，可分卷积大幅减少复杂度到O(k ⋅n⋅d + n⋅d2)。然而，即使k = n，一个可分卷积的复杂度等同于self-attention层和point-wise前向层的组合，即我们的模型采用的方法。\n\n间接的好处是self-attention可以产生更具可解释性的模型。我们从我们的模型中研究attention的分布。每个attention head不仅清楚地学习执行不同的任务，许多似乎也展现出了与句子的句法和语义结构相关的行为。\n","tags":["深度学习","自注意力机制","机器翻译"],"categories":["论文笔记"]}]